import pandas as pd
import yaml
from sklearn.feature_extraction.text import CountVectorizer
from tensorflow.keras.preprocessing.text import Tokenizer
from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score

import wandb
import tensorflow as tf
import pickle as pk
from models.ModelFactory import ModelFactory
from siamese_recurrent_network import prepare_training_data, siameseRN, loss
from utils.data_utils import get_data
from utils.file_utils import get_file_name


# Load configuration file
with open('config.yaml', 'r') as file:
    config = yaml.safe_load(file)

# Start a new wandb run to track this script
wandb.init(
    project="B&M-URLs",
    config=config
)

# Get and preprocess data
file_path = get_file_name('', config['model']['name'])

model = None
evals = None
if config['data']['approach'] == 'numerical':

    X_train, y_train = get_data(config['data']['train_path'], config['data']['features'], config['data']['target'])
    X_test, y_test = get_data(config['data']['test_path'], config['data']['features'], config['data']['target'])

    # vectorize data
    vectorizer = CountVectorizer()
    X_train = vectorizer.fit_transform(X_train)
    X_test = vectorizer.transform(X_test)
    file = open('vectorizer.pickle', 'wb')
    pk.dump(vectorizer, file, protocol=pk.HIGHEST_PROTOCOL)

    # Create model
    model = ModelFactory.create_model(config['model']['name'], X_train, y_train, X_test, y_test,
                                      config['model']['parameters'])

    # Train and predict
    model.train()
    y_pred = model.predict()

    file = open(file_path, 'wb')
    pk.dump(model, file, protocol=pk.HIGHEST_PROTOCOL)

    # Calculate evaluation metrics
    evals = model.get_evaluation_metrics()
elif config['data']['approach'] == 'comparative':
    train = pd.read_csv(config['data']['train_path'])
    test = pd.read_csv(config['data']['test_path'])
    tokenizer = Tokenizer(char_level=True)
    tokenizer.fit_on_texts(train['url1'])
    train_text2seq_1, train_text2seq_2, train_label = prepare_training_data(train, tokenizer)
    test_text2seq_1, test_text2seq_2, test_label = prepare_training_data(test, tokenizer)

    # Get model
    num_word = len(tokenizer.word_index) + 1
    model, optimizer = siameseRN(num_word)


    print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))

    margin = 1
    model.compile(loss=loss(margin=margin), optimizer="adam", metrics=["accuracy"])  # RMSprop
    model.summary()

    model.fit([train_text2seq_1, train_text2seq_2, ], train_label, epochs=config['model']['parameters']['epochs'],
              batch_size=16, verbose=1)

    file = open(file_path, 'wb')
    pk.dump(model, file, protocol=pk.HIGHEST_PROTOCOL)

    # Calculate evaluation metrics
    acc, loss = model.evaluate([test_text2seq_1, test_text2seq_2], test_label, verbose=1)

    # Predictions and ground truth labels
    y_pred = model.predict([test_text2seq_1, test_text2seq_2])
    y_pred_binary = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions

    # Calculate metrics
    conf_matrix = confusion_matrix(test_label, y_pred_binary)
    f1 = f1_score(test_label, y_pred_binary, zero_division=0)
    precision = precision_score(test_label, y_pred_binary, zero_division=0)
    recall = recall_score(test_label, y_pred_binary, zero_division=0)

    # Log metrics to Wandb
    evals = {
        'accuracy': acc,
        'loss': loss,
        'f1': f1,
        'precision': precision,
        'recall': recall,
    }
    wandb.log(evals)

    # Log confusion matrix as a matrix
    wandb.log({
        "cm": conf_matrix.tolist()
    })

# Log metrics to Wandb
wandb.log(evals)

# Finish the Wandb run
wandb.finish()